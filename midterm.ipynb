{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77416ab4-356d-4c96-a7dd-73844d9bd1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.downloader as api\n",
    "import textdistance\n",
    "import rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329cbdc4-e138-4e88-9e4a-87a2de99624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "model = api.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcce974-e796-41eb-b8d9-e3cf5f4df6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'train_with_label.txt'\n",
    "dev_filename = 'dev_with_label.txt'\n",
    "test_filename = 'test_without_label.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c73ffa-7c7e-438a-b325-a4c2bd1e78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    s = s.replace(' ,', ',')\n",
    "    s = s.replace('$ ', '$')\n",
    "    s = s.replace(\" '\", \"'\")\n",
    "    s = s.replace('``', '\"')\n",
    "    s = s.replace(\"''\", '\"')\n",
    "    s = s.replace(' .', '.')\n",
    "    s = s.replace(' ?', '?')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97aaf763-58aa-4dc3-8a19-9e5df2814ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readdf(filename, has_label=True):\n",
    "    with open(filename) as file:\n",
    "        buffer = file.readlines()\n",
    "        \n",
    "        col_names = ['id', 'sentence1', 'sentence2']\n",
    "        if has_label:\n",
    "            col_names.append('similar')\n",
    "            \n",
    "        df = pd.DataFrame([row.split('\\t') for row in buffer], columns=col_names)\n",
    "        if has_label:\n",
    "            df.similar = df.similar.apply(lambda x: int(x.rstrip()))\n",
    "        \n",
    "        df.sentence1 = df.sentence1.apply(lambda x: preprocess(x.lower()))\n",
    "        df.sentence2 = df.sentence2.apply(lambda x: preprocess(x.lower()))\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b2b8e1-af76-4250-8ea5-3e38db2701d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = readdf(train_filename)\n",
    "dev_df = readdf(dev_filename)\n",
    "test_df = readdf(test_filename, has_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c902a6-fa4d-4a1b-a7e0-c98bfdb8f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmd(s1, s2):\n",
    "    s1_split = [x for x in word_tokenize(s1) if x not in stop_words and len(x) > 1]\n",
    "    s2_split = [x for x in word_tokenize(s2) if x not in stop_words and len(x) > 1]\n",
    "    return model.wmdistance(s1_split, s2_split)\n",
    "\n",
    "def bleu(s1, s2):\n",
    "    return sentence_bleu([s1], s2)\n",
    "\n",
    "def meteor(s1, s2):\n",
    "    return single_meteor_score(s1.split(), s2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3fa439c-7cd6-4275-9db3-b2a713999e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(df, name, fn):\n",
    "    return pd.DataFrame(\n",
    "        [fn(s1,s2) for (s1,s2) in zip(df.sentence1, df.sentence2)],\n",
    "        columns=[name]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b071f31-6316-46e1-999d-094955ccde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(df):\n",
    "    return pd.concat([\n",
    "        feature(df, 'wmd', wmd),\n",
    "        feature(df, 'bleu', bleu),\n",
    "        feature(df, 'meteor', meteor),\n",
    "        feature(df, 'jaccard', textdistance.jaccard.normalized_similarity),\n",
    "        feature(df, 'damerau', rapidfuzz.distance.DamerauLevenshtein.normalized_similarity),\n",
    "    ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88961e4d-3b51-47e3-aff5-67ab109fbccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features(train_df)\n",
    "X_dev = features(dev_df)\n",
    "X_test = features(test_df)\n",
    "\n",
    "y_train = train_df.similar\n",
    "y_dev = dev_df.similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a6813bc-489f-4d88-a07f-b47fe1f120f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6367403314917127"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cc0adb0-e038-43f4-811f-ab8d27d64324",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = lr.predict(X_test)\n",
    "\n",
    "results_df = pd.concat([test_df.id, pd.DataFrame(y_test, columns=['similar'])], axis=1)\n",
    "results_df.to_csv('EricNguyen_test_result.txt', sep='\\t', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
